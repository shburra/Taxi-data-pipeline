# Taxi Data ETL Pipeline

## ğŸ“Œ Project Overview
This project builds an **ETL (Extract, Transform, Load) pipeline** for NYC taxi trip data. The pipeline automates:
- Data ingestion from public sources
- Data cleaning and transformation
- Storage in a PostgreSQL/SQLite database
- Exploratory data analysis with SQL and Python
- Deployment with Docker and Apache Airflow (optional)

## ğŸ“‚ Project Structure
nyc-taxi-data-pipeline/
â”‚â”€â”€ data/                   # Directory for datasets
â”‚   â”œâ”€â”€ raw/                # Raw data files (downloaded)
â”‚   â”œâ”€â”€ processed/          # Cleaned and transformed data
â”‚
â”‚â”€â”€ scripts/                # Python scripts for ETL process
â”‚   â”œâ”€â”€ download_data.py    # Script to download NYC taxi data
â”‚   â”œâ”€â”€ clean_data.py       # Script to clean and preprocess data
â”‚   â”œâ”€â”€ load_data.py        # Script to load data into database
â”‚
â”‚â”€â”€ notebooks/              # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ data_exploration.ipynb  # Initial data exploration
â”‚
â”‚â”€â”€ README.md               # Project documentation
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ .gitignore              # Files and folders to ignore in Git


## ğŸš€ Getting Started

### 1ï¸âƒ£ **Clone the Repository**
```sh
git clone https://github.com/your-username/taxi-data-pipeline.git
cd taxi-data-pipeline

### 2ï¸âƒ£ **Set Up a Virtual Environment (Optional but Recommended)**
python -m venv venv
source venv/bin/activate  # On Mac/Linux
venv\Scripts\activate     # On Windows

### 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

### 4ï¸âƒ£ Run the Data Pipeline
python scripts/download_data.py  # Download raw data
python scripts/clean_data.py     # Process data
python scripts/load_data.py      # Load data into the database

